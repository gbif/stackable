# Default values for GBIF HDFS cluster using Stackable HDFS operator.

# Override name of the cluster
nameOverride: ""
# Override fullname of the cluster
fullnameOverride: ""

# Stackable versioning to override the version of the Stack component.
stackProduct: "414"
stackVersion: "23.7.0"

# Custom version for extended version airflow
# Uses the stackProduct value to tell the operator what version of configurations to use with the custom image
# Example of how to set custom image
# customImage: 
#  repository: docker.gbif.org
#  image: gbif/extended-stack-trino-image
#  tag: "1.0.0"

customImage: {}

# List of catalogs to configure
# Current supports hive and postgresql
# Leaving the nodes empty will result in the catalog for the specific node being skipped
# Example 
# catalogs:
#  hive:
#    # Name of the hive metastore
#    metastoreName: "gbif-hive-metastore"
#    # Name of the HDFS cluster
#    hdfsClusterName: "gbif-hdfs"
#  postgresql:
#    # Connection string for the postgres
#    url: "jdbc:postgresql://gbif.example:5432/a-database"
#    # User for the postgres
#    user: "a-user"
#    # Password for the postgres user
#    # Currently password is put into the catalog itself which isn't optimal, so be caution and use a minimal service user
#    password: "some-password"
catalogs: {}

# limit for per-node usage for queries
memPerNode: "5GB"
# limit for headroom per node
# headroom + limit per-node shouldn't exceed the total memory set per worker.
memHeadroom: "1GB"

persistedGeocodeLayerStorage:
  # If enabled will try to create a PVC for the given storage class. The storage class should be a volume that can be accessed by multiple containers
  enabled: false
  # Size of the pv
  capacity: '1Gi'
  # Storage class for the PVC to look for storage. Requirement that it can be accessed by multiple containers at the same time
  storageClass: nfs-client

# users that should be created for the cluster at cluster creation time
# example of who it could look:
# customUsers:
#   test1: test1Password
#   test2: test2Password
customUsers: []

# Enable logging via the vector aggregator
# Needs the name of configmap for discovery of the aggregator
logging:
  enabled: false
  discoveryMap: "gbif-vector-aggregator-discovery"

nodes:
  coordinator:
    replicas: 1
    cpu:
      min: '100m'
      max: '2000m'
    memory: '2Gi'
    storage:
      capacity: '4Gi'
    #GBIF specified nodeports for exposing the infrastructure to VMs outside the kubenetes cluster
    ports:
      tcp:
        appPort: 8443
        nodePort: 31443
  worker:
    replicas: 1
    cpu:
      min: '100m'
      max: '6000m'
    memory: '8Gi'
    storage:
      capacity: '8Gi'
    #GBIF specified nodeports for exposing the infrastructure to VMs outside the kubenetes cluster
    ports: []
  
nodeSelector: {}