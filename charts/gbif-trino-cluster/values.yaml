# Default values for GBIF HDFS cluster using Stackable HDFS operator.

# Override name of the cluster
nameOverride: ""
# Override fullname of the cluster
fullnameOverride: ""

# Stackable versioning to override the version of the Stack component.
stackProduct: "428"
stackVersion: "24.3.0"

# Uses the stackProduct value to tell the operator what version of configurations to use with the custom image
# custom image allows customer to change the repository if they want to their own acting as a proxy or
# use an extended version of the image
# Example of how to set custom image
# customImage: 
#  enabled: true
#  repository: docker.gbif.org/your-team
#  extended:
#    enabled: true
#    image: a-extended-stackable-image
#    tag: "1.0.5"
customImage:
  enabled: false

# List of catalogs to configure
# Current supports hive and postgresql
# Leaving the nodes empty will result in the catalog for the specific node being skipped
# Example 
# catalogs:
#  hive:
#    # Name of the hive metastore
#    metastoreName: "gbif-hive-metastore"
#    # Name of the HDFS cluster
#    hdfsClusterName: "gbif-hdfs"
#  postgresql:
#    # Connection string for the postgres
#    url: "jdbc:postgresql://gbif.example:5432/a-database"
#    # User for the postgres
#    user: "a-user"
#    # Password for the postgres user
#    # Currently password is put into the catalog itself which isn't optimal, so be caution and use a minimal service user
#    password: "some-password"
catalogs: {}

# limit for per-node usage for queries
memPerNode: "5GB"
# limit for headroom per node
# headroom + limit per-node shouldn't exceed the total memory set per worker.
memHeadroom: "1GB"

geocodeLayer:
  # If enabled will try to create a PVC for the given storage class. The storage class should be a volume that can be accessed by multiple containers
  enabled: false
  # Server address
  server: localhost
  # Path
  mountPath: /trino/default

# users that should be created for the cluster at cluster creation time
# example of who it could look:
# customUsers:
#   test1: test1Password
#   test2: test2Password
customUsers: []

# Enable logging via the vector aggregator
# Needs the name of configmap for discovery of the aggregator
logging:
  # property for enable vector logging
  enabled: false
  # DisoveryMap for the connection the aggregator pod
  discoveryMap: "gbif-vector-aggregator-discovery"
  # Configured which vector itself logs on its own.
  vectorLogLevel: "WARN"

# Listenerclass for the stackable component
listenerClass: "cluster-internal"

# Set if to use custome stackable secret backend
# A temp function that at somepoint is going to be deprecated

customSecretBackend:
  enabled: false
  secretName: a-secret
  lifetime: "1d"

# Support for Yunikorn queuing
# By default it is disabled.
# The idea with enabling yunikorn for components is that we can fence the infrastructure components from works done in Spark, Trino etc.
yunikorn:
  enabled: false
  # Name of the overall application for all the pods within the queue
  appId: "trino"
  # Queue to place the pods in
  queue: "root.namespace.infra"

nodes:
  coordinator:
    replicas: 1
    cpu:
      min: '100m'
      max: '2000m'
    memory: '2Gi'
    logLevel: "INFO"
    storage:
      capacity: '4Gi'
    #GBIF specified nodeports for exposing the infrastructure to VMs outside the kubenetes cluster
    ports:
      tcp:
        appPort: 8443
        nodePort: 31443
  worker:
    replicas: 1
    cpu:
      min: '100m'
      max: '6000m'
    memory: '8Gi'
    logLevel: "INFO"
    storage:
      capacity: '8Gi'
    #GBIF specified nodeports for exposing the infrastructure to VMs outside the kubenetes cluster
    ports: []
  
nodeSelector: {}

clusterOperation:
  reconciliationPaused: false
  stopped: false

# Added possiblity to set a specfic stoargeClass to use for object
# Leave empty to use clusters default storageClass
storageClass: