# Default values for the GBIF Spark application for creating a table in the registry with a list of gridded datasets.
# Name of the application, chart uses the name to find the .jar file.
appName: "gbif-occurrence-download-spark"

# Stackable tag to use for the Spark application.
stackTag: 3.3.0-stackable23.1.0

# Main class for starting the Spark process.
appClass: org.gbif.occurrence.download.spark.SparkDownloads

#Mode for installing. This is an implemtantion for selecting which objects to install.
## all: Installs both spark application and configmaps - will fail if configmap already exists
## config: Installs the configmaps maps into a namespace
## app: Installs the spark application
# The use case is for enabling templating only the application for use in Airflows or start an instance of spark within necessary updating the configsmaps
installMode: config

# Ressource configuration for spark driver.
driver:
  # Number of cores for the Spark driver.
  core: 2
  # Memory for the Spark driver.
  mem: 2048m

# Ressource configuration for spark executors.
executor:
  # Number of cores for each executor.
  core: 6
  # Memory for each executor.
  mem: 10240m
  # Number of executors.
  instances: 6

# Application configs
apiUrl: http\://api.gbif-dev2.org/v1/
coreTermName: Occurrence
createTablesDynamically: false
es:
  connectTimeout: 7000
  hosts: ""
  index:
    nested: false
    type: OCCURRENCE
    name: occurrence_dev2
  socketTimeout: 120000
hadoopJobtracker: ""
hbaseTable: occurrence
hdfs:
  lock:
    connection:
      maxRetries: 5
      sleepTimeMs: 100
    name: hdfsview
    namespace: dev_index_lock
    path: /hive/
  namenode: ""
hive:
  db: ""
  metastoreUris: ""
  server2: ""
  user: ""
  warehouseDir: ""
occurrence:
  download:
    bionomiaReducer:
      memory: 10000
      opts: -Xmx8G
    fileMaxRecords: 1000
    hdfsTmpDir: /tmp/
    hdfsOutputPath: ""
    hiveHdfsOut: ""
    job:
      maxThreads: 3
      minRecords: 200
    link: ""
    maxConnectionPool: 10
    maxGlobalThreads: 10
    tmpDir: /tmp/
    ws:
      password: ""
      username: ""
    zookeeper:
      downloadsNamespace: dev_occurrencedownload
      indicesNamespace: dev_index_lock
      lockName: occDownloadJobsCounter
      maxRetries: 10
      sleepTime: 1000
  envPrefix: dev2
  environment: dev2
  hdfsBuildFrequency: ${coord\:days(1)}
registryWsUrl: http\://api.gbif-dev2.org/v1/
synctables: false
tableName: occurrence
wfPrefix: occurrence
zkConnectionString: ""
