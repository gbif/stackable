apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ include "gbif-chart-lib.releaseName" . }}-pod-templates
data:
  executor-pod-template.yaml: |
    apiVersion: v1
    kind: Pod
    spec:
      containers:
      - name: spark-shell-executor
        image: "docker.stackable.tech/stackable/spark-k8s:{{ .Values.stackProduct }}-stackable{{ .Values.stackVersion }}"
        resources:
          request:
            cpu: {{ .Values.nodes.executor.cpu.min }}
            memory: {{ .Values.nodes.executor.memory }}
          limit:
            cpu: {{ .Values.nodes.executor.cpu.max }}
            memory: {{ .Values.nodes.executor.memory }}
        env:
        - name: SPARK_CONF_DIR
          value: /stackable/spark/conf
        - name: HADOOP_CONF_DIR
          value: /etc/hadoop/conf
        volumeMounts:
        - mountPath: /etc/hadoop/conf/core-site.xml
          name: hadoop-env
          subPath: core-site.xml
        - mountPath: /etc/hadoop/conf/hdfs-site.xml
          name: hadoop-env
          subPath: hdfs-site.xml
        - mountPath: /etc/hadoop/conf/hive-site.xml
          name: hive-env
          subPath: hive-site.xml
        - mountPath: /etc/hadoop/conf/hbase-site.xml
          name: hbase-env
          subPath: hbase-site.xml
      securityContext:
        fsGroup: 1000
        runAsGroup: 1000
        runAsUser: 1000
      volumes:
        - name: hadoop-env
          configMap:
            name: {{ .Values.hdfs.clusterName }}
            items:
            - key: core-site.xml
              path: core-site.xml
            - key: hdfs-site.xml
              path: hdfs-site.xml
        - name: hive-env
          configMap:
            name: {{ .Values.hive.clusterName }}-custom
            items:
            - key: hive-site.xml
              path: hive-site.xml
        - name: hbase-env
          configMap:
            name: {{ .Values.hbase.clusterName }}
            items:
            - key: hbase-site.xml
              path: hbase-site.xml
  driver-pod-template.yaml: |
    apiVersion: v1
    kind: Pod
    spec:
      containers:
      - name: spark-shell-driver
        image: "docker.stackable.tech/stackable/spark-k8s:{{ .Values.stackProduct }}-stackable{{ .Values.stackVersion }}"
        resources:
          requests:
            cpu: {{ .Values.nodes.driver.cpu.min }}
            memory: {{ .Values.nodes.driver.memory }}
          limits:
            cpu: {{ .Values.nodes.driver.cpu.max }}
            memory: {{ .Values.nodes.driver.memory }}
        env:
        - name: SPARK_CONF_DIR
          value: /stackable/spark/conf
        - name: HADOOP_CONF_DIR
          value: /etc/hadoop/conf
        volumeMounts:
        - mountPath: /etc/hadoop/conf/core-site.xml
          name: hadoop-env
          subPath: core-site.xml
        - mountPath: /etc/hadoop/conf/hdfs-site.xml
          name: hadoop-env
          subPath: hdfs-site.xml
        - mountPath: /etc/hadoop/conf/hive-site.xml
          name: hive-env
          subPath: hive-site.xml
        - mountPath: /etc/hadoop/conf/hbase-site.xml
          name: hbase-env
          subPath: hbase-site.xml
      securityContext:
        fsGroup: 1000
        runAsGroup: 1000
        runAsUser: 1000
      volumes:
        - name: hadoop-env
          configMap:
            name: {{ .Values.hdfs.clusterName }}
            items:
            - key: core-site.xml
              path: core-site.xml
            - key: hdfs-site.xml
              path: hdfs-site.xml
        - name: hive-env
          configMap:
            name: {{ .Values.hive.clusterName }}-custom
            items:
            - key: hive-site.xml
              path: hive-site.xml
        - name: hbase-env
          configMap:
            name: {{ .Values.hbase.clusterName }}
            items:
            - key: hbase-site.xml
              path: hbase-site.xml