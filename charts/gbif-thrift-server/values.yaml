# Override name of the cluster
nameOverride: ""
# Override fullname of the cluster
fullnameOverride: ""

label:
  app.kubernetes.io/component: thrift
  app.kubernetes.io/instance: gbif-thrift-server
# Stackable tag to override the version of the Stack component.
stackProduct: "2.4.17"
stackVersion: "24.3.0"

# Uses the stackProduct value to tell the operator what version of configurations to use with the custom image
# custom image allows customer to change the repository if they want to their own acting as a proxy or
# use an extended version of the image
# Example of how to set custom image
# customImage: 
#  enabled: true
#  repository: docker.gbif.org/your-team
#  extended:
#    enabled: true
#    image: a-extended-stackable-image
#    tag: "1.0.5"
customImage:
  enabled: false

# Enable logging via the vector aggregator
# Needs the name of configmap for discovery of the aggregator
logging:
  # property for enable vector logging
  enabled: false
  # Service that access the vector aggregator
  vectorService: gbif-vector-aggregator
  # Configured which vector itself logs on its own.
  vectorLogLevel: "WARN"

# Support for Yunikorn queuing
# By default it is disabled.
# The idea with enabling yunikorn for components is that we can fence the infrastructure components from works done in Spark, Trino etc.
yunikorn:
  enabled: false
  # Name of the overall application for all the pods within the queue
  appId: "hbase"
  # Queue to place the pods in
  queue: "root.default"

# Ressource configuration for spark driver.
nodes:
  # Client deployment diff
  thrift:
    # Number of pods for the client
    replicas: 1
    # CPU settings for the driver  
    cpu:
      min: "1000m"
      max: "3000m"
    # Memory for the Spark driver.
    memory: "3Gi"
    # Funky dev calculated value
    # 80 procent of the total pod allocation
    heapSize: "2456m"
    # Ports used to create service
    ports: 
      thrift:
        appPort: 9090
        nodePort: 31990
    # Example of how nodeAffinity could look
    # nodeAffinity: 
    #   requiredDuringSchedulingIgnoredDuringExecution:
    #     nodeSelectorTerms:
    #     - matchExpressions:
    #       - key: a_label
    #         operator: In
    #         values:
    #         - some_value
    nodeAffinity: {}
    # Example of how podAntiAffinity could look
    # podAntiAffinity:
    #   requiredDuringSchedulingIgnoredDuringExecution:
    #   - labelSelector:
    #       matchLabels:
    #         app.kubernetes.io/name: thrift
    #     topologyKey: kubernetes.io/hostname
    podAntiAffinity: {}

hdfs:
  clusterName: "gbif-hdfs"

hive:
  clusterName: "gbif-hive-metastore"

hbase:
  clusterName: "gbif-hbase"