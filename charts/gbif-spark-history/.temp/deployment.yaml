apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ default .Chart.Name .Values.overrideName }}
  labels:
    app: {{ .Values.label }}
spec:
  replicas: 1
  selector:
    matchLabels:
      app: {{ .Values.label }}
  template:
    metadata:
      labels:
        app: {{ .Values.label }}
    spec:
      serviceAccountName: {{ default .Chart.Name .Values.overrideName }}
      securityContext:
        fsGroup: 1000
        runAsGroup: 1000
        runAsUser: 1000
      volumes:
        - name: {{ default .Chart.Name .Values.overrideName }}-core
          configMap:
            name: {{ .Values.hdfs.clusterId }}
            items:
            - key: core-site.xml
              path: core-site.xml
            - key: hdfs-site.xml
              path: hdfs-site.xml
      containers:
      - name: {{ default .Chart.Name .Values.overrideName }}-container
        image: {{ .Values.image }}
        command: 
          - /sbin/tini
          - -s
          - --
          - /stackable/spark/bin/spark-class
          - -Dspark.history.fs.logDirectory=/data/ # Needs to point to the s3 bucket ?
          - org.apache.soark.deploy.history.HistoryServer
        env:
          - name: SPARK_CONF_DIR
            value: /stackable/spark/conf
          - name: HADOOP_CONF_DIR
            value: /etc/hadoop/conf
        volumeMounts:
        - name: {{ default .Chart.Name .Values.overrideName }}-core
          mountPath: /etc/hadoop/conf/core-site.xml
          subPath: core-site.xml
        - name: {{ default .Chart.Name .Values.overrideName }}-core
          mountPath: /etc/hadoop/conf/hdfs-site.xml
          subPath: hdfs-site.xml