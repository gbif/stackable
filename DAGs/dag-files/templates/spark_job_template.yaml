apiVersion: spark.stackable.tech/v1alpha1
kind: SparkApplication
metadata:
  name: {{ run_id }}
spec:
  version: {{ dag_run.params.version }}
  image: docker.gbif.org/{{ dag_run.params.component }}:{{ dag_run.params.version }}
  sparkImage: docker.stackable.tech/stackable/spark-k8s:3.3.0-stackable23.4.1
  mode: cluster
  mainApplicationFile: local:///stackable/spark/jobs/{{ dag_run.params.component }}.jar
  mainClass: {{ dag_run.params.main }}
  args:
{%- for arg in dag_run.params.args %}
    - "{{arg}}"
{%- endfor %}
  deps:
    repositories:
      - https://repository.gbif.org/repository/central/
    packages:
      - org.apache.spark:spark-avro_2.12:3.3.1
      - com.fasterxml.jackson.dataformat:jackson-dataformat-xml:2.13.3
  sparkConf:
{%- raw %}
     "spark.driver.extraJavaOptions": "-XX:+UseConcMarkSweepGC"
     "spark.executor.extraJavaOptions": "-XX:+UseConcMarkSweepGC"
     "spark.jars.ivy": "/tmp"
     "spark.broadcast.compress": "true"
     "spark.checkpoint.compress": "true"
     "spark.executor.memoryOverhead": "4096"
     "spark.executor.heartbeatInterval": "10s"
     "spark.network.timeout": "60s"
     "spark.io.compression.codec": "lz4"
     "spark.rdd.compress": "true"
     "spark.driver.extraClassPath": "/etc/hadoop/conf/"
     "spark.executor.extraClassPath": "/etc/hadoop/conf/"
{%- endraw %}
  volumes:
    - name: config
      configMap:
        name: {{ dag_run.params.componentConfig }}-conf
    - name: hdfs-env
      configMap:
        name: {{ dag_run.params.hdfsClusterName }}
        items:
        - key: core-site.xml
          path: core-site.xml
        - key: hdfs-site.xml
          path: hdfs-site.xml
    - name: hive-env
      configMap:
        name: {{ dag_run.params.hiveClusterName }}-custom
        items:
        - key: hive-site.xml
          path: hive-site.xml
  driver:
    resources:
      cpu:
        min: "100m"
        max: "{{ dag_run.params.driverCores }}"
      memory:
        limit: "{{ dag_run.params.driverMemory }}"
    volumeMounts:
      - name: config
        mountPath: /etc/gbif
      - name: hdfs-env
        mountPath: /etc/hadoop/conf/core-site.xml
        subPath: core-site.xml
      - name: hdfs-env
        mountPath: /etc/hadoop/conf/hdfs-site.xml
        subPath: hdfs-site.xml
      - name: hive-env
        mountPath: /etc/hadoop/conf/hive-site.xml
        subPath: hive-site.xml
  executor:
    instances: {{ dag_run.params.executorInstances }}
    resources:
      cpu:
        min: "100m"
        max: "{{ dag_run.params.executorCores }}"
      memory:
        limit: "{{ dag_run.params.executorMemory }}"
    volumeMounts:
      - name: config
        mountPath: /etc/gbif
      - name: hdfs-env
        mountPath: /etc/hadoop/conf/core-site.xml
        subPath: core-site.xml
      - name: hdfs-env
        mountPath: /etc/hadoop/conf/hdfs-site.xml
        subPath: hdfs-site.xml
      - name: hive-env
        mountPath: /etc/hadoop/conf/hive-site.xml
        subPath: hive-site.xml